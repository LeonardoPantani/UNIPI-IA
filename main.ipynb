{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial Intelligence for Cybersecurity Project\n",
    "### Dataset used: \"Malicious URLs dataset\" by Manu Siddhartha\n",
    "\n",
    "### Candidates: Riccardo Fantasia & Leonardo Pantani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_raw = pd.read_csv(\"UNIPI-IA-dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = [\"malware\", \"phishing\", \"defacement\", \"benign\"]\n",
    "\n",
    "df_raw[\"type\"] = pd.Categorical(df_raw[\"type\"], categories=types, ordered=True)\n",
    "df = df_raw.sort_values(by=\"type\").drop_duplicates(subset=\"url\", keep=\"first\")\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly import graph_objects as go\n",
    "\n",
    "count = df['type'].value_counts()\n",
    "colors = [\n",
    "    '#FF6633', '#FFB399', '#FF33FF', '#FFFF99', '#00B3E6',\n",
    "    '#E6B333', '#3366E6', '#999966', '#99FF99', '#B34D4D'\n",
    "]\n",
    "fig = go.Figure(data=[go.Bar(x=count.index, y=count, marker=dict(color=colors))])\n",
    "fig.update_layout(\n",
    "    xaxis_title='Types',\n",
    "    yaxis_title='Count',\n",
    "    title='Count of Different Types of URLs',\n",
    "    plot_bgcolor='black',\n",
    "    paper_bgcolor='black',\n",
    "    font=dict(color='white')\n",
    ")\n",
    "fig.update_xaxes(tickfont=dict(color='white'))\n",
    "fig.update_yaxes(tickfont=dict(color='white'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estriamo le 23 features da ogni url nel dataset intero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.features_extractors import (extract_feature_ip_use,extract_feature_url_entropy,extract_feature_num_digits,extract_feature_url_length,extract_feature_num_query_parameters,extract_feature_num_fragments,extract_feature_num_percent20,extract_feature_num_at_signs,extract_feature_hashttp,extract_feature_hashttps,extract_feature_dot_number,extract_feature_num_www, extract_feature_directory_num,extract_feature_embed_domain_number,extract_feature_suspiciousurl,extract_feature_count_percent,extract_feature_count_dash,extract_feature_count_equal,extract_feature_is_shortened,extract_feature_hostname_length,extract_feature_first_directory_length,extract_feature_top_level_domain_length,extract_feature_letter_count)\n",
    "\n",
    "df['feature_ip_use'] = df['url'].apply(extract_feature_ip_use)\n",
    "df['feature_url_entropy'] = df['url'].apply(extract_feature_url_entropy)\n",
    "df['feature_num_digits'] = df['url'].apply(extract_feature_num_digits)\n",
    "df['feature_url_length'] = df['url'].apply(extract_feature_url_length)\n",
    "df['feature_num_query_parameters'] = df['url'].apply(extract_feature_num_query_parameters)\n",
    "df['feature_num_fragments'] = df['url'].apply(extract_feature_num_fragments)\n",
    "df['feature_num_percent20'] = df['url'].apply(extract_feature_num_percent20)\n",
    "df['feature_num_at_signs'] = df['url'].apply(extract_feature_num_at_signs)\n",
    "df['feature_hashttp'] = df['url'].apply(extract_feature_hashttp)\n",
    "df['feature_hashttps'] = df['url'].apply(extract_feature_hashttps)\n",
    "df['feature_dot_number'] = df['url'].apply(extract_feature_dot_number)\n",
    "df['feature_num_www'] = df['url'].apply(extract_feature_num_www)\n",
    "df['feature_directory_num'] = df['url'].apply(extract_feature_directory_num)\n",
    "df['feature_embed_domain_number'] = df['url'].apply(extract_feature_embed_domain_number)\n",
    "df['feature_suspiciousurl'] = df['url'].apply(extract_feature_suspiciousurl)\n",
    "df['feature_count_percent'] = df['url'].apply(extract_feature_count_percent)\n",
    "df['feature_count_dash'] = df['url'].apply(extract_feature_count_dash)\n",
    "df['feature_count_equal'] = df['url'].apply(extract_feature_count_equal)\n",
    "df['feature_is_shortened'] = df['url'].apply(extract_feature_is_shortened)\n",
    "df['feature_hostname_length'] = df['url'].apply(extract_feature_hostname_length)\n",
    "df['feature_first_directory_length'] = df['url'].apply(extract_feature_first_directory_length)\n",
    "df['feature_top_level_domain_length'] = df['url'].apply(extract_feature_top_level_domain_length)\n",
    "df['feature_letter_count'] = df['url'].apply(extract_feature_letter_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostriamo una HeatMap di correlazione tra le feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Filtra solo le colonne con prefisso \"feature\"\n",
    "features_df = df[[col for col in df.columns if col.startswith('feature')]]\n",
    "features_df = features_df.rename(columns=lambda x: x.replace('feature_', ''))\n",
    "\n",
    "# Crea e mostra la heatmap\n",
    "correlation_matrix = features_df.corr()\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", cbar=True, square=True)\n",
    "plt.title(\"Heatmap delle Correlazioni tra le Feature\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data la forte correlazione tra:\n",
    "- embed_domain_number <-> hashttp\n",
    "- count_equal <-> num_query_parameters\n",
    "- url_length <-> letter_count\n",
    "\n",
    "... e data la stretta somiglianza logica delle funzioni abbiamo deciso di rimuovere:\n",
    "- embed_domain_number\n",
    "- count_equal\n",
    "- url_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot di count_equal <-> num_query_parameters\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(features_df['count_equal'], features_df['num_query_parameters'], alpha=0.7, color='orange')\n",
    "plt.title('Scatter Plot: count_equals vs num_query_parameters')\n",
    "plt.xlabel('count_equals')\n",
    "plt.ylabel('num_query_parameters')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Scatter plot di url_length <-> letter_count\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(features_df['url_length'], features_df['letter_count'], alpha=0.7, color='green')\n",
    "plt.title('Scatter Plot: url_length vs letter_count')\n",
    "plt.xlabel('url_length')\n",
    "plt.ylabel('letter_count')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Facciamo un box plot per ogni feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['feature_url_entropy', 'feature_num_digits', 'feature_url_length', 'feature_num_query_parameters', 'feature_num_fragments', 'feature_num_percent20', 'feature_num_at_signs', 'feature_dot_number', 'feature_num_www', 'feature_directory_num', 'feature_embed_domain_number', 'feature_count_percent', 'feature_count_dash', 'feature_count_equal', 'feature_hostname_length', 'feature_first_directory_length', 'feature_top_level_domain_length', 'feature_letter_count']\n",
    "for feature in features:\n",
    "    plt.figure(figsize=(12, 1.5))\n",
    "    plt.boxplot(df[feature].dropna(), vert=False, patch_artist=True, showmeans=True)\n",
    "    plt.title(f'Box Plot of {feature}', fontsize=10)\n",
    "    plt.xlabel(feature, fontsize=8)\n",
    "    plt.gca().yaxis.set_visible(False)\n",
    "    plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rimuoviamo le seguenti feature:\n",
    "- embed_domain_number\n",
    "- count_equal\n",
    "- url_length\n",
    "\n",
    "Testeremo successivamente allenando il modello di classificazione sul dataset originale e su quello ripulito dalle suddette feature, per valutare l'effettivo miglioramento in termini di classificazione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"feature_embed_domain_number\", \"feature_count_equal\", \"feature_url_length\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Filtra solo le colonne con prefisso \"feature\"\n",
    "features_df = df[[col for col in df.columns if col.startswith('feature')]]\n",
    "features_df = features_df.rename(columns=lambda x: x.replace('feature_', ''))\n",
    "\n",
    "# Crea e mostra la heatmap\n",
    "correlation_matrix = features_df.corr()\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", cbar=True, square=True)\n",
    "plt.title(\"Heatmap delle Correlazioni tra le Feature\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suddividiamo il dataset in training e test set con un rapporto 80% e 20%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from utils.utils import printInfo\n",
    "\n",
    "train_ratio = 0.80\n",
    "test_ratio = 0.20\n",
    "x_train_unbalanced, x_test, y_train_unbalanced, y_test = train_test_split(df.drop(columns=[\"type\", \"url\"]).copy(), df[\"type\"].copy(), test_size=1-train_ratio, shuffle=True, stratify=df[\"type\"].copy())\n",
    "\n",
    "printInfo(\"training\", y_train_unbalanced)\n",
    "printInfo(\"test\", y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un aspetto che notiamo dall'output soprastante è lo sbilanciamento, in termini di numero di sample, della classe malevola rispetto alla benigna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "def balance_data_undersample_benign(x_train, y_train):\n",
    "    class_counts = Counter(y_train)\n",
    "    other_classes_count = sum([class_counts[label] for label in class_counts if label != \"benign\"])\n",
    "    benign_target = other_classes_count\n",
    "    undersampling_strategy = {\"benign\": benign_target}\n",
    "    rus = RandomUnderSampler(sampling_strategy=undersampling_strategy, random_state=42)\n",
    "    x_train_resampled, y_train_resampled = rus.fit_resample(x_train, y_train)\n",
    "    return x_train_resampled, y_train_resampled\n",
    "\n",
    "x_train, y_train = balance_data_undersample_benign(x_train_unbalanced, y_train_unbalanced)\n",
    "printInfo(\"training bilanciato\", y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si vorrebbe fare uno scaling dei dati in modo da avere circa media 0 e varianza 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nell'ottica di una classificazione eseguita mantenendo gli outliers, si procede inizialmente con una normalizzazione RobustScaler che mantiene meglio l'effetto degli outliers. Dopodiché si procederà con una Z-Normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "scaler = RobustScaler()\n",
    "x_train_scaled_robust = scaler.fit_transform(x_train)\n",
    "x_test_scaled_robust = scaler.transform(x_test)\n",
    "\n",
    "x_train_scaled_robust = pd.DataFrame(x_train_scaled_robust, columns=x_train.columns, index=x_train.index)\n",
    "x_test_scaled_robust = pd.DataFrame(x_test_scaled_robust, columns=x_test.columns, index=x_test.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "x_train_scaled_standard = scaler.fit_transform(x_train)\n",
    "x_test_scaled_standard = scaler.transform(x_test)\n",
    "\n",
    "x_train_scaled_standard = pd.DataFrame(x_train_scaled_standard, columns=x_train.columns, index=x_train.index)\n",
    "x_test_scaled_standard = pd.DataFrame(x_test_scaled_standard, columns=x_test.columns, index=x_test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASSIFICATORI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier_randomforest = RandomForestClassifier()\n",
    "classifier_randomforest.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "y_pred = classifier_randomforest.predict(x_test)\n",
    "y_pred_proba = classifier_randomforest.predict_proba(x_test)\n",
    "\n",
    "report = classification_report(y_test, y_pred, target_names=['benign', 'phishing', 'defacement', 'malware'])\n",
    "print(report)\n",
    "\n",
    "auc_score = roc_auc_score(y_test, y_pred_proba, multi_class='ovr')\n",
    "print(f\"AUC Score: {auc_score:.4f}\")\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred, labels=np.unique(y_test))\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['benign', 'phishing', 'defacement', 'malware'], yticklabels=['benign', 'phishing', 'defacement', 'malware'])\n",
    "plt.xlabel('Classe predetta')\n",
    "plt.ylabel('Classe reale')\n",
    "plt.title('Matrice di Confusione')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOGISTIC REGRESSION\n",
    "Data la natura di questo classificatore, è necessario categorizzare le classi phishing, defacement, malware in un'unica che considereremo come \"maligna\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raggruppa le classi in 'malignant' e 'benign'\n",
    "y_train = y_train.replace({\"malware\": \"malignant\", \"phishing\": \"malignant\", \"defacement\": \"malignant\", \"benign\": \"benign\"})\n",
    "y_test = y_test.replace({\"malware\": \"malignant\", \"phishing\": \"malignant\", \"defacement\": \"malignant\", \"benign\": \"benign\"})\n",
    "\n",
    "printInfo(\"training\", y_train)\n",
    "printInfo(\"test\", y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Con Robust Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier_logisticregression = LogisticRegression()\n",
    "classifier_logisticregression.fit(x_train_scaled_robust, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "y_pred = classifier_logisticregression.predict(x_test_scaled_robust)\n",
    "y_pred_proba = classifier_logisticregression.predict_proba(x_test_scaled_robust)\n",
    "\n",
    "report = classification_report(y_test, y_pred, target_names=['benign', 'malignant'])\n",
    "print(report)\n",
    "\n",
    "auc_score = roc_auc_score(y_test, y_pred_proba[:, 1])\n",
    "print(f\"AUC Score: {auc_score:.4f}\")\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred, labels=np.unique(y_test))\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['benign', 'malignant'], yticklabels=['benign', 'malignant'])\n",
    "plt.xlabel('Classe predetta')\n",
    "plt.ylabel('Classe reale')\n",
    "plt.title('Matrice di Confusione [con RobustScaler]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Con Standard Scaler (Z-Normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier_logisticregression = LogisticRegression()\n",
    "classifier_logisticregression.fit(x_train_scaled_standard, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "y_pred = classifier_logisticregression.predict(x_test_scaled_standard)\n",
    "y_pred_proba = classifier_logisticregression.predict_proba(x_test_scaled_standard)\n",
    "\n",
    "report = classification_report(y_test, y_pred, target_names=['benign', 'malignant'])\n",
    "print(report)\n",
    "\n",
    "auc_score = roc_auc_score(y_test, y_pred_proba[:, 1])\n",
    "print(f\"AUC Score: {auc_score:.4f}\")\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred, labels=np.unique(y_test))\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['benign', 'malignant'], yticklabels=['benign', 'malignant'])\n",
    "plt.xlabel('Classe predetta')\n",
    "plt.ylabel('Classe reale')\n",
    "plt.title('Matrice di Confusione [con Z-Normalization]')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
